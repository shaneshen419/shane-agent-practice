from typing import Dict, Any, List, Optional, Tuple, Generator
from openai import OpenAI
import re
import base64
from io import BytesIO
from PIL import Image
from datetime import datetime, timedelta
from icalendar import Calendar, Event

class LLMClient:
    """é€šç”¨LLMå®¢æˆ·ç«¯åŸºç±»"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "qwen-turbo"):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client_kwargs = {
            "api_key": self.api_key,
            "timeout": None
        }
        
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
            
        self.client = OpenAI(**client_kwargs)


class TravelPlannerLLM(LLMClient):
    """æ—…è¡Œè§„åˆ’ä¸“ç”¨LLMå®¢æˆ·ç«¯"""
    
    def generate_itinerary_stream(self, destination: str, num_days: int) -> Generator[str, None, None]:
        """æµå¼ç”Ÿæˆæ—…è¡Œè¡Œç¨‹"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œå…·æœ‰ä¸°å¯Œçš„å…¨çƒæ—…è¡ŒçŸ¥è¯†ã€‚
è¯·ä¸ºç”¨æˆ·åˆ›å»ºè¯¦ç»†çš„ã€å®ç”¨çš„æ—…è¡Œè¡Œç¨‹ã€‚

è¦æ±‚ï¼š
1. ä¸ºæ¯ä¸€å¤©åˆ›å»ºè¯¦ç»†çš„æ´»åŠ¨å®‰æ’
2. åŒ…æ‹¬æ™¯ç‚¹æ¨èã€é¤å…å»ºè®®ã€ä½å®¿é€‰æ‹©
3. æä¾›äº¤é€šæ–¹å¼ã€æœ€ä½³æ¸¸è§ˆæ—¶é—´ã€é¢„ç®—ä¼°è®¡
4. ç¡®ä¿è¡Œç¨‹èŠ‚å¥åˆç†ï¼Œä¸è¿‡äºç´§å¼ 
5. ä½¿ç”¨æ¸…æ™°çš„"Day 1:", "Day 2:"ç­‰æ ¼å¼æ ‡é¢˜
6. è€ƒè™‘å½“åœ°æ–‡åŒ–å’Œå®é™…æƒ…å†µ"""

        user_prompt = f"""è¯·ä¸º{destination}åˆ›å»ºä¸€ä¸ª{num_days}å¤©çš„è¯¦ç»†æ—…è¡Œè¡Œç¨‹ã€‚

è¯·åŒ…æ‹¬ï¼š
- æ¯æ—¥å…·ä½“çš„æ™¯ç‚¹å’Œæ´»åŠ¨å®‰æ’
- é¤å…å’Œç¾é£Ÿæ¨è
- ä½å®¿å»ºè®®
- äº¤é€šæç¤º
- é¢„ç®—ä¼°è®¡
- å½“åœ°æ–‡åŒ–æ´å¯Ÿ

è¯·ç¡®ä¿æ¯å¤©éƒ½æœ‰æ˜ç¡®çš„"Day X:"æ ‡é¢˜ï¼Œæ–¹ä¾¿è½¬æ¢ä¸ºæ—¥å†äº‹ä»¶ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                top_p=0.9,
                max_tokens=4096,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            raise Exception(f"ç”Ÿæˆè¡Œç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def generate_itinerary(self, destination: str, num_days: int) -> str:
        """éæµå¼ç”Ÿæˆæ—…è¡Œè¡Œç¨‹"""
        full_text = ""
        for chunk in self.generate_itinerary_stream(destination, num_days):
            full_text += chunk
        return full_text


class VisionLLMClient(LLMClient):
    """è§†è§‰è¯†åˆ«ä¸“ç”¨LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "qwen-vl-plus"):
        super().__init__(api_key, base_url, model)
    
    def encode_image_to_base64(self, image: Image.Image, format: str = "JPEG") -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        buffered = BytesIO()
        
        # å¦‚æœæ˜¯PNGä¸”æœ‰é€æ˜åº¦ï¼Œä¿æŒPNGæ ¼å¼
        if format.upper() == "PNG" or (hasattr(image, 'mode') and image.mode == 'RGBA'):
            format = "PNG"
        else:
            format = "JPEG"
            # å¦‚æœå›¾åƒæœ‰é€æ˜åº¦ï¼Œè½¬æ¢ä¸ºRGB
            if image.mode in ('RGBA', 'LA'):
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = background
        
        image.save(buffered, format=format, quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return f"data:image/{format.lower()};base64,{img_str}"
    
    def get_system_prompt(self, analysis_type: str) -> str:
        """æ ¹æ®åˆ†æç±»å‹è·å–ç³»ç»Ÿæç¤º"""
        system_prompts = {
            "comprehensive": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æä¸“å®¶ï¼Œå…·æœ‰æ•é”çš„è§†è§‰æ´å¯ŸåŠ›å’Œä¸°å¯Œçš„çŸ¥è¯†èƒŒæ™¯ã€‚
è¯·å¯¹å›¾åƒè¿›è¡Œå…¨é¢æ·±å…¥çš„åˆ†æï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

ğŸ“‹ **åŸºæœ¬ä¿¡æ¯è¯†åˆ«**
- ä¸»è¦å¯¹è±¡å’Œå…ƒç´ 
- åœºæ™¯å’Œç¯å¢ƒæè¿°
- é¢œè‰²ã€å…‰çº¿ã€æ„å›¾åˆ†æ

ğŸ¨ **è‰ºæœ¯å’Œè®¾è®¡è§’åº¦**
- è§†è§‰é£æ ¼å’Œç¾å­¦ç‰¹ç‚¹
- æ„å›¾æŠ€å·§å’Œè§†è§‰å¹³è¡¡
- è‰²å½©æ­é…å’Œæ°›å›´è¥é€ 

ğŸ” **ç»†èŠ‚è§‚å¯Ÿ**
- é‡è¦çš„ç»†èŠ‚å’Œç‰¹å¾
- èƒŒæ™¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
- å¯èƒ½çš„è±¡å¾æ„ä¹‰æˆ–éšå«ä¿¡æ¯

ğŸ“Š **ç»“æ„åŒ–è¾“å‡º**
è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„emojiå’Œåˆ†æ®µï¼Œè®©å†…å®¹æ˜“è¯»ä¸”ç¾è§‚ã€‚""",

            "simple": """ä½ æ˜¯ä¸€ä¸ªå›¾åƒè¯†åˆ«åŠ©æ‰‹ï¼Œè¯·ç®€æ´å‡†ç¡®åœ°æè¿°å›¾åƒçš„ä¸»è¦å†…å®¹ã€‚

åŒ…æ‹¬ï¼š
- ä¸»è¦å¯¹è±¡
- åœºæ™¯æè¿°  
- å…³é”®ç‰¹å¾

è¯·ç”¨ç®€æ´çš„è¯­è¨€ï¼Œé‡ç‚¹çªå‡ºæœ€é‡è¦çš„ä¿¡æ¯ã€‚""",

            "detailed": """ä½ æ˜¯ä¸€ä¸ªè¯¦ç»†çš„å›¾åƒåˆ†æä¸“å®¶ï¼Œè¯·æä¾›æ·±å…¥å…¨é¢çš„å›¾åƒåˆ†ææŠ¥å‘Šã€‚

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. è§†è§‰å…ƒç´ è¯†åˆ«
2. åœºæ™¯å’Œç¯å¢ƒåˆ†æ
3. æŠ€æœ¯å‚æ•°è¯„ä¼°ï¼ˆå¦‚å¯è§ï¼‰
4. è‰ºæœ¯å’Œç¾å­¦è¯„ä»·
5. å¯èƒ½çš„ç”¨é€”å’Œæ„ä¹‰
6. æ”¹è¿›å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰

è¯·ä½¿ç”¨ä¸“ä¸šçš„æœ¯è¯­å’Œç»“æ„åŒ–çš„æ ¼å¼ã€‚""",

            "creative": """ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„è§†è§‰æ•…äº‹å®¶ï¼Œè¯·ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ–¹å¼æè¿°è¿™å¼ å›¾ç‰‡ã€‚

å¯ä»¥åŒ…æ‹¬ï¼š
- å¯Œæœ‰æƒ³è±¡åŠ›çš„åœºæ™¯æè¿°
- å¯èƒ½çš„æ•…äº‹èƒŒæ™¯
- æƒ…æ„Ÿå’Œæ°›å›´æ„Ÿå—
- åˆ›æ„è”æƒ³å’Œç±»æ¯”

è®©æè¿°æ—¢å‡†ç¡®åˆå¯Œæœ‰è‰ºæœ¯æ„ŸæŸ“åŠ›ã€‚"""
        }
        
        return system_prompts.get(analysis_type, system_prompts["comprehensive"])
    
    def analyze_image_stream(self, image: Image.Image, analysis_type: str = "comprehensive") -> Generator[str, None, None]:
        """æµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        
        system_prompt = self.get_system_prompt(analysis_type)
        
        user_prompt = f"""è¯·å¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œ{analysis_type}åˆ†æã€‚

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰é‡è¦å…ƒç´ 
2. ä½¿ç”¨æ¸…æ™°çš„ç»“æ„å’Œæ ¼å¼
3. åŒ…å«é€‚å½“çš„emojiå’Œæ ‡é¢˜æ¥ç¾åŒ–æ’ç‰ˆ
4. æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿå’Œä¿¡æ¯

è¯·å¼€å§‹ä½ çš„åˆ†æï¼š"""
        
        # ç¼–ç å›¾åƒ
        base64_image = self.encode_image_to_base64(image)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": base64_image,
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.3,
                top_p=0.9,
                max_tokens=4096,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            raise Exception(f"å›¾åƒåˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def analyze_image(self, image: Image.Image, analysis_type: str = "comprehensive") -> str:
        """éæµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        full_text = ""
        for chunk in self.analyze_image_stream(image, analysis_type):
            full_text += chunk
        return full_text
