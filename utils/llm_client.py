from typing import Dict, Any, List, Optional, Tuple, Generator
from openai import OpenAI
import re
import base64
from io import BytesIO
from PIL import Image
from datetime import datetime, timedelta
from icalendar import Calendar, Event
import json


class LLMClient:
    """é€šç”¨LLMå®¢æˆ·ç«¯åŸºç±»"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "qwen-turbo"):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client_kwargs = {
            "api_key": self.api_key,
            "timeout": None
        }
        
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
            
        self.client = OpenAI(**client_kwargs)


class TravelPlannerLLM(LLMClient):
    """æ—…è¡Œè§„åˆ’ä¸“ç”¨LLMå®¢æˆ·ç«¯"""
    
    def generate_itinerary_stream(self, destination: str, num_days: int) -> Generator[str, None, None]:
        """æµå¼ç”Ÿæˆæ—…è¡Œè¡Œç¨‹"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œå…·æœ‰ä¸°å¯Œçš„å…¨çƒæ—…è¡ŒçŸ¥è¯†ã€‚
è¯·ä¸ºç”¨æˆ·åˆ›å»ºè¯¦ç»†çš„ã€å®ç”¨çš„æ—…è¡Œè¡Œç¨‹ã€‚

è¦æ±‚ï¼š
1. ä¸ºæ¯ä¸€å¤©åˆ›å»ºè¯¦ç»†çš„æ´»åŠ¨å®‰æ’
2. åŒ…æ‹¬æ™¯ç‚¹æ¨èã€é¤å…å»ºè®®ã€ä½å®¿é€‰æ‹©
3. æä¾›äº¤é€šæ–¹å¼ã€æœ€ä½³æ¸¸è§ˆæ—¶é—´ã€é¢„ç®—ä¼°è®¡
4. ç¡®ä¿è¡Œç¨‹èŠ‚å¥åˆç†ï¼Œä¸è¿‡äºç´§å¼ 
5. ä½¿ç”¨æ¸…æ™°çš„"Day 1:", "Day 2:"ç­‰æ ¼å¼æ ‡é¢˜
6. è€ƒè™‘å½“åœ°æ–‡åŒ–å’Œå®é™…æƒ…å†µ"""

        user_prompt = f"""è¯·ä¸º{destination}åˆ›å»ºä¸€ä¸ª{num_days}å¤©çš„è¯¦ç»†æ—…è¡Œè¡Œç¨‹ã€‚

è¯·åŒ…æ‹¬ï¼š
- æ¯æ—¥å…·ä½“çš„æ™¯ç‚¹å’Œæ´»åŠ¨å®‰æ’
- é¤å…å’Œç¾é£Ÿæ¨è
- ä½å®¿å»ºè®®
- äº¤é€šæç¤º
- é¢„ç®—ä¼°è®¡
- å½“åœ°æ–‡åŒ–æ´å¯Ÿ

è¯·ç¡®ä¿æ¯å¤©éƒ½æœ‰æ˜ç¡®çš„"Day X:"æ ‡é¢˜ï¼Œæ–¹ä¾¿è½¬æ¢ä¸ºæ—¥å†äº‹ä»¶ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                top_p=0.9,
                max_tokens=4096,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            raise Exception(f"ç”Ÿæˆè¡Œç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def generate_itinerary(self, destination: str, num_days: int) -> str:
        """éæµå¼ç”Ÿæˆæ—…è¡Œè¡Œç¨‹"""
        full_text = ""
        for chunk in self.generate_itinerary_stream(destination, num_days):
            full_text += chunk
        return full_text

    # +++ æ–°å¢ï¼šæ ‡å‡†åŒ–çš„ä»»åŠ¡æ‰§è¡Œå…¥å£ï¼Œç”¨äºè¢«MCPè°ƒç”¨ +++
    def execute_task(self, task_description: str, context: dict) -> str:
        """
        ä½œä¸ºå·¥å…·è¢«MCPè°ƒç”¨æ—¶æ‰§è¡Œçš„å…·ä½“ä»»åŠ¡ã€‚
        task_description: MCPåˆ†é…çš„å…·ä½“æŒ‡ä»¤, e.g., "ä¸ºå»å·´é»çš„5æ—¥æ¸¸åˆ¶å®šä¸€ä¸ªè¡Œç¨‹"
        context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œå¯èƒ½åŒ…å«å‰ç½®ä»»åŠ¡çš„ç»“æœ
        """
        print(f"âœˆï¸ TravelPlannerLLM æ­£åœ¨æ‰§è¡Œ: {task_description}")
        # ä½¿ç”¨LLMæ¥è§£æä»»åŠ¡æè¿°ä¸­çš„ç›®çš„åœ°å’Œå¤©æ•°ä¿¡æ¯
        parsed_info = self._parse_task_with_llm(task_description)
        
        destination = parsed_info.get("destination")
        days = parsed_info.get("days")
        
        # å¦‚æœLLMè§£æå¤±è´¥ï¼Œåˆ™å°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ
        if not destination or not days:
            import re
            print("ğŸ”„ LLMè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ...")
            
            # å°è¯•æå–ç›®çš„åœ° - ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å¼
            destination_match = re.search(r'å®‰æ’ä¸€ä¸‹([\u4e00-\u9fa5]{2,5})(?=å›½åº†)', task_description)
            destination = destination_match.group(1) if destination_match else None
            
            # å°è¯•æå–å¤©æ•° - åŒ¹é…ä¸­æ–‡æ•°å­—æˆ–é˜¿æ‹‰ä¼¯æ•°å­—
            days_match = re.search(r'(?:(\d+)|([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]))å¤©', task_description)
            days = days_match.group(1) if days_match else None
            # å¦‚æœåŒ¹é…åˆ°ä¸­æ–‡æ•°å­—ï¼Œéœ€è¦è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
            days_dict = {'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5', 'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10'}
            if not days and days_match and days_match.group(2):
                days = days_dict.get(days_match.group(2))
            
            if not destination or not days:
                return f"é”™è¯¯ï¼šæ— æ³•ä»ä»»åŠ¡ '{task_description}' ä¸­è§£æå‡ºç›®çš„åœ°å’Œå¤©æ•°ã€‚"
        
        num_days = int(days)

        # ä½¿ç”¨æµå¼æ–¹æ³•æ¥å®Œæˆä»»åŠ¡
        try:
            result = ""
            for chunk in self.generate_itinerary_stream(destination, num_days):
                result += chunk
            print(f"âœˆï¸ TravelPlannerLLM å®Œæˆä»»åŠ¡ã€‚")
            return result
        except Exception as e:
            return f"æ—…è¡Œè§„åˆ’æ‰§è¡Œå¤±è´¥: {e}"

    def _parse_task_with_llm(self, task_description: str) -> dict:
        """ä½¿ç”¨LLMæ¥æ™ºèƒ½è§£æä»»åŠ¡æè¿°ä¸­çš„ç›®çš„åœ°å’Œå¤©æ•°ä¿¡æ¯"""
        try:
            parse_prompt = f"""
è¯·ä»ä»¥ä¸‹ä»»åŠ¡æè¿°ä¸­æå–æ—…è¡Œè§„åˆ’ä¿¡æ¯ï¼š

ä»»åŠ¡æè¿°: \"{task_description}\"

è¯·è¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{{
    \"destination\": \"ç›®çš„åœ°åŸå¸‚åç§°\",
    \"days\": å¤©æ•°ï¼ˆæ•°å­—ï¼‰
}}

å¦‚æœæ— æ³•ç¡®å®šæŸä¸ªä¿¡æ¯ï¼Œè¯·è¿”å›nullã€‚
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": parse_prompt}],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            print(f"ğŸ§  LLMè§£æç»“æœ: {result}")
            return result
            
        except Exception as e:
            print(f"âš ï¸ LLMè§£æå¤±è´¥: {e}")
            return {}

class VisionLLMClient(LLMClient):
    """è§†è§‰è¯†åˆ«ä¸“ç”¨LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "qwen-vl-plus"):
        super().__init__(api_key, base_url, model)
    
    def encode_image_to_base64(self, image: Image.Image, format: str = "JPEG") -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        buffered = BytesIO()
        
        # å¦‚æœæ˜¯PNGä¸”æœ‰é€æ˜åº¦ï¼Œä¿æŒPNGæ ¼å¼
        if format.upper() == "PNG" or (hasattr(image, 'mode') and image.mode == 'RGBA'):
            format = "PNG"
        else:
            format = "JPEG"
            # å¦‚æœå›¾åƒæœ‰é€æ˜åº¦ï¼Œè½¬æ¢ä¸ºRGB
            if image.mode in ('RGBA', 'LA'):
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = background
        
        image.save(buffered, format=format, quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return f"data:image/{format.lower()};base64,{img_str}"
    
    def get_system_prompt(self, analysis_type: str) -> str:
        """æ ¹æ®åˆ†æç±»å‹è·å–ç³»ç»Ÿæç¤º"""
        system_prompts = {
            "comprehensive": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æä¸“å®¶ï¼Œå…·æœ‰æ•é”çš„è§†è§‰æ´å¯ŸåŠ›å’Œä¸°å¯Œçš„çŸ¥è¯†èƒŒæ™¯ã€‚
è¯·å¯¹å›¾åƒè¿›è¡Œå…¨é¢æ·±å…¥çš„åˆ†æï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

ğŸ“‹ **åŸºæœ¬ä¿¡æ¯è¯†åˆ«**
- ä¸»è¦å¯¹è±¡å’Œå…ƒç´ 
- åœºæ™¯å’Œç¯å¢ƒæè¿°
- é¢œè‰²ã€å…‰çº¿ã€æ„å›¾åˆ†æ

ğŸ¨ **è‰ºæœ¯å’Œè®¾è®¡è§’åº¦**
- è§†è§‰é£æ ¼å’Œç¾å­¦ç‰¹ç‚¹
- æ„å›¾æŠ€å·§å’Œè§†è§‰å¹³è¡¡
- è‰²å½©æ­é…å’Œæ°›å›´è¥é€ 

ğŸ” **ç»†èŠ‚è§‚å¯Ÿ**
- é‡è¦çš„ç»†èŠ‚å’Œç‰¹å¾
- èƒŒæ™¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
- å¯èƒ½çš„è±¡å¾æ„ä¹‰æˆ–éšå«ä¿¡æ¯

ğŸ“Š **ç»“æ„åŒ–è¾“å‡º**
è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„emojiå’Œåˆ†æ®µï¼Œè®©å†…å®¹æ˜“è¯»ä¸”ç¾è§‚ã€‚""",

            "simple": """ä½ æ˜¯ä¸€ä¸ªå›¾åƒè¯†åˆ«åŠ©æ‰‹ï¼Œè¯·ç®€æ´å‡†ç¡®åœ°æè¿°å›¾åƒçš„ä¸»è¦å†…å®¹ã€‚

åŒ…æ‹¬ï¼š
- ä¸»è¦å¯¹è±¡
- åœºæ™¯æè¿°  
- å…³é”®ç‰¹å¾

è¯·ç”¨ç®€æ´çš„è¯­è¨€ï¼Œé‡ç‚¹çªå‡ºæœ€é‡è¦çš„ä¿¡æ¯ã€‚""",

            "detailed": """ä½ æ˜¯ä¸€ä¸ªè¯¦ç»†çš„å›¾åƒåˆ†æä¸“å®¶ï¼Œè¯·æä¾›æ·±å…¥å…¨é¢çš„å›¾åƒåˆ†ææŠ¥å‘Šã€‚

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. è§†è§‰å…ƒç´ è¯†åˆ«
2. åœºæ™¯å’Œç¯å¢ƒåˆ†æ
3. æŠ€æœ¯å‚æ•°è¯„ä¼°ï¼ˆå¦‚å¯è§ï¼‰
4. è‰ºæœ¯å’Œç¾å­¦è¯„ä»·
5. å¯èƒ½çš„ç”¨é€”å’Œæ„ä¹‰
6. æ”¹è¿›å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰

è¯·ä½¿ç”¨ä¸“ä¸šçš„æœ¯è¯­å’Œç»“æ„åŒ–çš„æ ¼å¼ã€‚""",

            "creative": """ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„è§†è§‰æ•…äº‹å®¶ï¼Œè¯·ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ–¹å¼æè¿°è¿™å¼ å›¾ç‰‡ã€‚

å¯ä»¥åŒ…æ‹¬ï¼š
- å¯Œæœ‰æƒ³è±¡åŠ›çš„åœºæ™¯æè¿°
- å¯èƒ½çš„æ•…äº‹èƒŒæ™¯
- æƒ…æ„Ÿå’Œæ°›å›´æ„Ÿå—
- åˆ›æ„è”æƒ³å’Œç±»æ¯”

è®©æè¿°æ—¢å‡†ç¡®åˆå¯Œæœ‰è‰ºæœ¯æ„ŸæŸ“åŠ›ã€‚"""
        }
        
        return system_prompts.get(analysis_type, system_prompts["comprehensive"])
    
    def analyze_image_stream(self, image: Image.Image, analysis_type: str = "comprehensive") -> Generator[str, None, None]:
        """æµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        
        system_prompt = self.get_system_prompt(analysis_type)
        
        user_prompt = f"""è¯·å¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œ{analysis_type}åˆ†æã€‚

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰é‡è¦å…ƒç´ 
2. ä½¿ç”¨æ¸…æ™°çš„ç»“æ„å’Œæ ¼å¼
3. åŒ…å«é€‚å½“çš„emojiå’Œæ ‡é¢˜æ¥ç¾åŒ–æ’ç‰ˆ
4. æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿå’Œä¿¡æ¯

è¯·å¼€å§‹ä½ çš„åˆ†æï¼š"""
        
        # ç¼–ç å›¾åƒ
        base64_image = self.encode_image_to_base64(image)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": base64_image,
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.3,
                top_p=0.9,
                max_tokens=4096,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            raise Exception(f"å›¾åƒåˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def analyze_image(self, image: Image.Image, analysis_type: str = "comprehensive") -> str:
        """éæµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        full_text = ""
        for chunk in self.analyze_image_stream(image, analysis_type):
            full_text += chunk
        return full_text
    
    # +++ æ–°å¢ï¼šæ ‡å‡†åŒ–çš„ä»»åŠ¡æ‰§è¡Œå…¥å£ï¼Œç”¨äºè¢«MCPè°ƒç”¨ +++
    def execute_task(self, task_description: str, context: dict) -> str:
        """
        ä½œä¸ºå·¥å…·è¢«MCPè°ƒç”¨æ—¶æ‰§è¡Œçš„å…·ä½“ä»»åŠ¡ã€‚
        task_description: MCPåˆ†é…çš„å…·ä½“æŒ‡ä»¤, e.g., "åˆ†æè¿™å¼ å›¾ç‰‡é‡Œçš„ä¸»è¦ç‰©ä½“"
        context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å« image_path æˆ– image_url
        """
        print(f"ğŸ‘ï¸ VisionLLMClient æ­£åœ¨æ‰§è¡Œ: {task_description}")
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–å›¾ç‰‡ä¿¡æ¯
        # å‡è®¾MCPä¼šæŠŠéœ€è¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„æ”¾å…¥context
        image_path = context.get("image_path")
        if not image_path:
            return "é”™è¯¯ï¼šä¸Šä¸‹æ–‡ä¸­æœªæ‰¾åˆ°éœ€è¦åˆ†æçš„å›¾ç‰‡è·¯å¾„(image_path)ã€‚"
            
        try:
            image = Image.open(image_path)
            # ä»ä»»åŠ¡æè¿°ä¸­è§£æåˆ†æç±»å‹ï¼Œå¦‚æœæ²¡æŒ‡å®šï¼Œå°±ç”¨é»˜è®¤çš„
            analysis_type = "comprehensive"
            if "ç®€å•" in task_description or "ç®€æ´" in task_description:
                analysis_type = "simple"
            elif "è¯¦ç»†" in task_description:
                analysis_type = "detailed"
            
            # è°ƒç”¨å·²æœ‰çš„éæµå¼æ–¹æ³•æ¥å®Œæˆä»»åŠ¡
            result = self.analyze_image(image, analysis_type)
            print(f"ğŸ‘ï¸ VisionLLMClient å®Œæˆä»»åŠ¡ã€‚")
            return result
        except Exception as e:
            return f"å›¾åƒåˆ†ææ‰§è¡Œå¤±è´¥: {e}"
        
class ReadmeViewerLLM(LLMClient):
    """READMEæŸ¥çœ‹å™¨çš„LLMé€‚é…å™¨"""
    
    def __init__(self, api_key: str, base_url: str, model: str = "qwen-turbo"):
        super().__init__(api_key, base_url, model)
        # å¯¼å…¥é¡µé¢åŠŸèƒ½
        try:
            import sys
            import os
            # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            if project_root not in sys.path:
                sys.path.append(project_root)
            
            from pages.readme.readme_page import readme_show_page
            self.readme_page = readme_show_page()
        except ImportError as e:
            print(f"âš ï¸ æ— æ³•å¯¼å…¥ ReadmePage: {e}")
            self.readme_page = None
    
    def execute_task(self, task_description: str, context: dict) -> str:
        """
        æ‰§è¡ŒREADMEç›¸å…³ä»»åŠ¡
        """
        print(f"ğŸ“– ReadmeViewerLLM æ­£åœ¨æ‰§è¡Œ: {task_description}")
        
        if not self.readme_page:
            return "é”™è¯¯ï¼šREADMEé¡µé¢åŠŸèƒ½æœªæ­£ç¡®åŠ è½½"
        
        try:
            # æ ¹æ®ä»»åŠ¡æè¿°åˆ¤æ–­è¦æ‰§è¡Œä»€ä¹ˆæ“ä½œ
            if "æ˜¾ç¤º" in task_description or "æŸ¥çœ‹" in task_description or "readme" in task_description.lower():
                # è°ƒç”¨READMEé¡µé¢çš„æ˜¾ç¤ºåŠŸèƒ½
                if hasattr(self.readme_page, 'display_readme'):
                    result = self.readme_page.display_readme()
                elif hasattr(self.readme_page, 'get_readme_content'):
                    result = self.readme_page.get_readme_content()
                else:
                    # å¦‚æœæ²¡æœ‰ç‰¹å®šæ–¹æ³•ï¼Œå°è¯•è°ƒç”¨ä¸»è¦æ–¹æ³•
                    result = "READMEå†…å®¹å·²æ˜¾ç¤º"
                
                return f"âœ… READMEæŸ¥çœ‹å®Œæˆï¼š{result}"
            else:
                return f"âœ… å·²å¤„ç†READMEç›¸å…³è¯·æ±‚ï¼š{task_description}"
                
        except Exception as e:
            error_msg = f"READMEåŠŸèƒ½æ‰§è¡Œå¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return error_msg


