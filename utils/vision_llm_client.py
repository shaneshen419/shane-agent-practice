from typing import Dict, Any, List, Optional, Tuple, Generator
from openai import OpenAI
import re
import base64
from io import BytesIO
from PIL import Image
from datetime import datetime, timedelta
from icalendar import Calendar, Event
import json
from utils.llm_client import LLMClient

class VisionLLMClient(LLMClient):
    """è§†è§‰è¯†åˆ«ä¸“ç”¨LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "qwen-vl-plus"):
        super().__init__(api_key, base_url, model)
    
    def encode_image_to_base64(self, image: Image.Image, format: str = "JPEG") -> str:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç """
        buffered = BytesIO()
        
        # å¦‚æœæ˜¯PNGä¸”æœ‰é€æ˜åº¦ï¼Œä¿æŒPNGæ ¼å¼
        if format.upper() == "PNG" or (hasattr(image, 'mode') and image.mode == 'RGBA'):
            format = "PNG"
        else:
            format = "JPEG"
            # å¦‚æœå›¾åƒæœ‰é€æ˜åº¦ï¼Œè½¬æ¢ä¸ºRGB
            if image.mode in ('RGBA', 'LA'):
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                image = background
        
        image.save(buffered, format=format, quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return f"data:image/{format.lower()};base64,{img_str}"
    
    def get_system_prompt(self, analysis_type: str) -> str:
        """æ ¹æ®åˆ†æç±»å‹è·å–ç³»ç»Ÿæç¤º"""
        system_prompts = {
            "comprehensive": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æä¸“å®¶ï¼Œå…·æœ‰æ•é”çš„è§†è§‰æ´å¯ŸåŠ›å’Œä¸°å¯Œçš„çŸ¥è¯†èƒŒæ™¯ã€‚
è¯·å¯¹å›¾åƒè¿›è¡Œå…¨é¢æ·±å…¥çš„åˆ†æï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

ğŸ“‹ **åŸºæœ¬ä¿¡æ¯è¯†åˆ«**
- ä¸»è¦å¯¹è±¡å’Œå…ƒç´ 
- åœºæ™¯å’Œç¯å¢ƒæè¿°
- é¢œè‰²ã€å…‰çº¿ã€æ„å›¾åˆ†æ

ğŸ¨ **è‰ºæœ¯å’Œè®¾è®¡è§’åº¦**
- è§†è§‰é£æ ¼å’Œç¾å­¦ç‰¹ç‚¹
- æ„å›¾æŠ€å·§å’Œè§†è§‰å¹³è¡¡
- è‰²å½©æ­é…å’Œæ°›å›´è¥é€ 

ğŸ” **ç»†èŠ‚è§‚å¯Ÿ**
- é‡è¦çš„ç»†èŠ‚å’Œç‰¹å¾
- èƒŒæ™¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
- å¯èƒ½çš„è±¡å¾æ„ä¹‰æˆ–éšå«ä¿¡æ¯

ğŸ“Š **ç»“æ„åŒ–è¾“å‡º**
è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„emojiå’Œåˆ†æ®µï¼Œè®©å†…å®¹æ˜“è¯»ä¸”ç¾è§‚ã€‚""",

            "simple": """ä½ æ˜¯ä¸€ä¸ªå›¾åƒè¯†åˆ«åŠ©æ‰‹ï¼Œè¯·ç®€æ´å‡†ç¡®åœ°æè¿°å›¾åƒçš„ä¸»è¦å†…å®¹ã€‚

åŒ…æ‹¬ï¼š
- ä¸»è¦å¯¹è±¡
- åœºæ™¯æè¿°  
- å…³é”®ç‰¹å¾

è¯·ç”¨ç®€æ´çš„è¯­è¨€ï¼Œé‡ç‚¹çªå‡ºæœ€é‡è¦çš„ä¿¡æ¯ã€‚""",

            "detailed": """ä½ æ˜¯ä¸€ä¸ªè¯¦ç»†çš„å›¾åƒåˆ†æä¸“å®¶ï¼Œè¯·æä¾›æ·±å…¥å…¨é¢çš„å›¾åƒåˆ†ææŠ¥å‘Šã€‚

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. è§†è§‰å…ƒç´ è¯†åˆ«
2. åœºæ™¯å’Œç¯å¢ƒåˆ†æ
3. æŠ€æœ¯å‚æ•°è¯„ä¼°ï¼ˆå¦‚å¯è§ï¼‰
4. è‰ºæœ¯å’Œç¾å­¦è¯„ä»·
5. å¯èƒ½çš„ç”¨é€”å’Œæ„ä¹‰
6. æ”¹è¿›å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰

è¯·ä½¿ç”¨ä¸“ä¸šçš„æœ¯è¯­å’Œç»“æ„åŒ–çš„æ ¼å¼ã€‚""",

            "creative": """ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„è§†è§‰æ•…äº‹å®¶ï¼Œè¯·ç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ–¹å¼æè¿°è¿™å¼ å›¾ç‰‡ã€‚

å¯ä»¥åŒ…æ‹¬ï¼š
- å¯Œæœ‰æƒ³è±¡åŠ›çš„åœºæ™¯æè¿°
- å¯èƒ½çš„æ•…äº‹èƒŒæ™¯
- æƒ…æ„Ÿå’Œæ°›å›´æ„Ÿå—
- åˆ›æ„è”æƒ³å’Œç±»æ¯”

è®©æè¿°æ—¢å‡†ç¡®åˆå¯Œæœ‰è‰ºæœ¯æ„ŸæŸ“åŠ›ã€‚"""
        }
        
        return system_prompts.get(analysis_type, system_prompts["comprehensive"])
    
    def analyze_image_stream(self, image: Image.Image, analysis_type: str = "comprehensive") -> Generator[str, None, None]:
        """æµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        
        system_prompt = self.get_system_prompt(analysis_type)
        
        user_prompt = f"""è¯·å¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œ{analysis_type}åˆ†æã€‚

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰é‡è¦å…ƒç´ 
2. ä½¿ç”¨æ¸…æ™°çš„ç»“æ„å’Œæ ¼å¼
3. åŒ…å«é€‚å½“çš„emojiå’Œæ ‡é¢˜æ¥ç¾åŒ–æ’ç‰ˆ
4. æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿå’Œä¿¡æ¯

è¯·å¼€å§‹ä½ çš„åˆ†æï¼š"""
        
        # ç¼–ç å›¾åƒ
        base64_image = self.encode_image_to_base64(image)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": base64_image,
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.3,
                top_p=0.9,
                max_tokens=4096,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            raise Exception(f"å›¾åƒåˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def analyze_image(self, image: Image.Image, analysis_type: str = "comprehensive") -> str:
        """éæµå¼åˆ†æå›¾ç‰‡å†…å®¹"""
        full_text = ""
        for chunk in self.analyze_image_stream(image, analysis_type):
            full_text += chunk
        return full_text
    
    # +++ æ–°å¢ï¼šæ ‡å‡†åŒ–çš„ä»»åŠ¡æ‰§è¡Œå…¥å£ï¼Œç”¨äºè¢«MCPè°ƒç”¨ +++
    def execute_task(self, task_description: str, context: dict) -> str:
        """
        ä½œä¸ºå·¥å…·è¢«MCPè°ƒç”¨æ—¶æ‰§è¡Œçš„å…·ä½“ä»»åŠ¡ã€‚
        task_description: MCPåˆ†é…çš„å…·ä½“æŒ‡ä»¤, e.g., "åˆ†æè¿™å¼ å›¾ç‰‡é‡Œçš„ä¸»è¦ç‰©ä½“"
        context: ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å« image_path æˆ– image_url
        """
        print(f"ğŸ‘ï¸ VisionLLMClient æ­£åœ¨æ‰§è¡Œ: {task_description}")
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–å›¾ç‰‡ä¿¡æ¯
        # å‡è®¾MCPä¼šæŠŠéœ€è¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„æ”¾å…¥context
        image_path = context.get("image_path")
        if not image_path:
            return "é”™è¯¯ï¼šä¸Šä¸‹æ–‡ä¸­æœªæ‰¾åˆ°éœ€è¦åˆ†æçš„å›¾ç‰‡è·¯å¾„(image_path)ã€‚"
            
        try:
            image = Image.open(image_path)
            # ä»ä»»åŠ¡æè¿°ä¸­è§£æåˆ†æç±»å‹ï¼Œå¦‚æœæ²¡æŒ‡å®šï¼Œå°±ç”¨é»˜è®¤çš„
            analysis_type = "comprehensive"
            if "ç®€å•" in task_description or "ç®€æ´" in task_description:
                analysis_type = "simple"
            elif "è¯¦ç»†" in task_description:
                analysis_type = "detailed"
            
            # è°ƒç”¨å·²æœ‰çš„éæµå¼æ–¹æ³•æ¥å®Œæˆä»»åŠ¡
            result = self.analyze_image(image, analysis_type)
            print(f"ğŸ‘ï¸ VisionLLMClient å®Œæˆä»»åŠ¡ã€‚")
            return result
        except Exception as e:
            return f"å›¾åƒåˆ†ææ‰§è¡Œå¤±è´¥: {e}"